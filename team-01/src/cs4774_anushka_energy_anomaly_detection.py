# -*- coding: utf-8 -*-
"""CS4774_Anushka_Energy_Anomaly_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bW8s77fPgZtnOxl3FqTPbJISxpi6Xp6b
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Input, LSTM, RepeatVector
from tensorflow.keras.models import Model
tf.random.set_seed(7)
np.random.seed(1)

from google.colab import drive
drive.mount('/content/drive')

data = '/content/drive/My Drive/archive/energy-anomaly-detection/train.csv'
df = pd.read_csv(data)
df

mean_reading = df.groupby('building_id')['meter_reading'].mean()
plt.figure(figsize=(20,10))
mean_reading.plot.bar()
plt.xticks([])
plt.show()

reading_counts = df.groupby('building_id')['meter_reading'].count()
building_with_most_data = reading_counts.idxmax()
max_readings_count = reading_counts.max()
print(f"Building with the most data (ID): {building_with_most_data}")
print(f"Number of readings: {max_readings_count}")

df = df[df['building_id'] == 118]
df

plt.figure(figsize=(12,6))
sns.lineplot(x=df['timestamp'], y=df['meter_reading'])
plt.title(f'Time Series of Energy Usage of Building 118')
plt.xlabel('Date and Time')
plt.ylabel('Energy Reading')
plt.xticks([])
plt.show()

# Calculate split indices chronologically
total_len = len(df)
train_end = int(total_len * 0.8)
val_end = int(total_len * 0.9) # 80% train + 10% validation

# Create dataframes for train, validation, and test sets
train_df = df[:train_end]
val_df = df[train_end:val_end]
test_df = df[val_end:]

train_data = train_df[['meter_reading']]
train_labels = train_df[['anomaly']]
val_data = val_df[['meter_reading']]
val_labels = val_df[['anomaly']]
test_data = test_df[['meter_reading']]
test_labels = test_df[['anomaly']]

# Normalized the time series using MinMaxScaler

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaled_train_data = scaler.fit_transform(train_data)
scaled_val_data = scaler.transform(val_data)
scaled_test_data = scaler.transform(test_data)

# Generated overlapping windows of fixed length to feed into the LSTM
# Not shuffling since time series and we don't want to be using future data to predict present

def create_sequences(data, seq_length):
    X = []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
    return np.array(X)

SEQ_LENGTH = 24

X_train = create_sequences(scaled_train_data, SEQ_LENGTH)
Y_train = train_labels.iloc[SEQ_LENGTH:]
X_val = create_sequences(scaled_val_data, SEQ_LENGTH)
Y_val = val_labels.iloc[SEQ_LENGTH:]
X_test = create_sequences(scaled_test_data, SEQ_LENGTH)
Y_test = test_labels.iloc[SEQ_LENGTH:]

def LSTM_compression(data):

  input_dim = data.shape[2]
  timesteps = data.shape[1]

  inputs = Input(shape=(timesteps, input_dim))
  encoded = LSTM(64, activation='relu', return_sequences=False, name="encoder")(inputs)
  decoded = RepeatVector(timesteps)(encoded)
  decoded = LSTM(64, activation='relu', return_sequences=True)(decoded)

  autoencoder = Model(inputs, decoded)
  autoencoder.compile(optimizer='adam', loss='mse')

  autoencoder.fit(data, data, epochs=30, batch_size=64, validation_split=0.1, shuffle=False)

  encoder_model = Model(inputs, encoded)
  latent_vectors = encoder_model.predict(data, verbose=1, batch_size=32)  # shape = (num_samples, 64)

  return encoder_model, latent_vectors

encoder_model, train_latent_vectors = LSTM_compression(X_train)

from sklearn.svm import OneClassSVM
from sklearn.metrics import precision_score, recall_score, f1_score
import pandas as pd
import numpy as np

# Assume you have your full data and labels:
# X_train_latent, y_train_labels (0 for normal, 1 for anomaly)
# X_test_latent, y_test_labels (0 for normal, 1 for anomaly)

def hyperparameter_tuning():
    best_score = 0
    best_params = {}
    precisions = []

    for nu_val in [0.1, 0.15, 0.2]:
        for gamma_val in ['auto', 'scale']:
            normal_train_vectors = train_latent_vectors[Y_train.iloc[:, 0] == 0]

            oc_svm = OneClassSVM(nu=nu_val, kernel='rbf', gamma=gamma_val)
            oc_svm.fit(normal_train_vectors)

            # Evaluate on the validation data
            # Predictions will be +1 (inlier/normal) or -1 (outlier/anomaly)
            val_latent_vectors = encoder_model.predict(X_val, verbose=0, batch_size = 32)
            val_predictions = oc_svm.predict(val_latent_vectors)

            # Remap predictions to 0 (normal) and 1 (anomaly) for comparison with y_test_labels
            remapped_predictions = np.zeros_like(val_predictions)
            remapped_predictions[val_predictions == -1] = 1

            # Calculate metrics
            precision = precision_score(Y_val, remapped_predictions, pos_label=1)
            precisions.append(precision)
            recall = recall_score(Y_val, remapped_predictions, pos_label=1)
            f1 = f1_score(Y_val, remapped_predictions, pos_label=1)

            print(f"Params: nu={nu_val}, gamma={gamma_val} | Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}")

            # Keep track of the model with the best Precision (TP/FP + TP)
            if precision > best_score:
                best_score = precision
                best_params = {'nu': nu_val, 'gamma': gamma_val}

    print(f"\nBest parameters found: {best_params} with Precision score of {best_score:.4f}")
    return best_params, best_score, precisions

best_params, best_score, precisions = hyperparameter_tuning()

test_latent_vectors = encoder_model.predict(X_test, verbose=0, batch_size = 32)

# Use OC-SVM model with best parameters from hyperparameter tuning
if best_params:
  oc_svm = OneClassSVM(nu=best_params['nu'], kernel='rbf', gamma=best_params['gamma'])
else:
  oc_svm = OneClassSVM(nu=0.1, kernel='rbf', gamma='auto')

# Train the OC-SVM model on the latent space vectors
# The model learns the boundary of the normal data distribution in this space
oc_svm.fit(train_latent_vectors)

# Predict using the OC-SVM
predictions = oc_svm.predict(test_latent_vectors)

# Remapping prediction labels
anomaly_labels = np.zeros_like(predictions)
anomaly_labels[predictions == -1] = 1

precision = precision_score(Y_test, anomaly_labels, pos_label=1)
recall = recall_score(Y_test, anomaly_labels, pos_label=1)
f1 = f1_score(Y_test, anomaly_labels, pos_label=1)

print(f"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}")

# Visualize the latent space with PCA

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
latent_pca = pca.fit_transform(test_latent_vectors)

plt.figure(figsize=(10, 6))
sns.scatterplot(x=latent_pca[:, 0], y=latent_pca[:, 1], hue=anomaly_labels, palette='viridis', s=50, alpha=0.7)
plt.title("One-Class SVM Anomaly Detection in Latent Space (PCA 2D)")
plt.xlabel("principal component 1")
plt.ylabel("principal component 2")
plt.grid(True)
plt.show()

# Apply KMeans clustering to group similar latent representations
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=2, random_state=42)
labels = kmeans.fit_predict(test_latent_vectors)

# We assume the larger cluster is "normal"
normal_cluster = np.bincount(labels).argmax()
anomaly_mask = labels != normal_cluster

# Convert boolean mask to integer labels (0 for normal, 1 for anomaly)
kmeans_anomaly_labels = np.zeros_like(anomaly_mask, dtype=int)
kmeans_anomaly_labels[anomaly_mask] = 1

# Calculate metrics
kmeans_precision = precision_score(Y_test, kmeans_anomaly_labels, pos_label=1)
kmeans_recall = recall_score(Y_test, kmeans_anomaly_labels, pos_label=1)
kmeans_f1 = f1_score(Y_test, kmeans_anomaly_labels, pos_label=1)

print(f"K-means Precision: {kmeans_precision:.4f}, Recall: {kmeans_recall:.4f}, F1-Score: {kmeans_f1:.4f}")

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
latent_pca = pca.fit_transform(test_latent_vectors)

plt.figure(figsize=(10, 6))
sns.scatterplot(x=latent_pca[:, 0], y=latent_pca[:, 1], hue=labels, palette='Set1', s=50, alpha=0.7)
plt.title("Kmeans cluster in latent space (PCA 2D)")
plt.xlabel("principal component 1")
plt.ylabel("principal component 2")
plt.grid(True)
plt.show()

# Clustering algorithm that identifies data points in sparse regions as noise or anomalies

from sklearn.cluster import DBSCAN

dbscan = DBSCAN(eps=0.5, min_samples=10)
clusters = dbscan.fit_predict(latent_pca)

# Initialize all points as 'normal' (class 0)
remapped_labels = np.zeros_like(clusters)
remapped_labels[clusters == -1] = 1

plt.figure(figsize=(10, 6))
# Color points based on their assigned cluster label
plt.scatter(latent_pca[:, 0], latent_pca[:, 1], c=clusters, cmap='viridis')
plt.xlabel('principal component 1')
plt.ylabel('principal component 2')
plt.title('DBSCAN Clustering Results (Anomalies as Class -1)')
plt.colorbar(label='Class Label (0: Normal, 1: Anomaly)')
plt.show()

# Calculate metrics
dbscan_precision = precision_score(Y_test, remapped_labels, pos_label=1)
dbscan_recall = recall_score(Y_test, remapped_labels, pos_label=1)
dbscan_f1 = f1_score(Y_test, remapped_labels, pos_label=1)

print(f"DBSCAN Precision: {dbscan_precision:.4f}, Recall: {dbscan_recall:.4f}, F1-Score: {dbscan_f1:.4f}")

plot_df = test_df.iloc[SEQ_LENGTH:].copy()

# Add predicted labels as new columns
plot_df['oc_svm_prediction'] = anomaly_labels
plot_df['kmeans_prediction'] = kmeans_anomaly_labels
plot_df['dbscan_prediction'] = remapped_labels

def plot_anomalies_comparison(df, model_pred_col, title):
    plt.figure(figsize=(15, 7))

    # Plot the original meter readings
    sns.lineplot(x='timestamp', y='meter_reading', data=df, label='Meter Reading (Normal)', color='gray', alpha=0.6)

    # Highlight ACTUAL anomalies in red
    actual_anomalies = df[df['anomaly'] == 1]
    sns.scatterplot(x='timestamp', y='meter_reading', data=actual_anomalies, color='red', marker='x', s=100, label='Actual Anomaly')

    # Highlight PREDICTED anomalies in orange/gold
    predicted_anomalies = df[df[model_pred_col] == 1]
    sns.scatterplot(x='timestamp', y='meter_reading', data=predicted_anomalies, color='gold', marker='o', s=50, label='Predicted Anomaly')

    plt.title(title)
    plt.xlabel('Date and Time')
    plt.ylabel('Energy Reading')
    plt.legend()
    plt.xticks([])
    plt.show()

# Generate plots for each model:
plot_anomalies_comparison(plot_df, 'oc_svm_prediction', 'OC SVM: Actual vs Predicted Anomalies over Time')

plot_anomalies_comparison(plot_df, 'kmeans_prediction', 'K-Means: Actual vs Predicted Anomalies over Time')

plot_anomalies_comparison(plot_df, 'dbscan_prediction', 'DBSCAN: Actual vs Predicted Anomalies over Time')